15.09.2022 07:07

- AI is any system that has the ability to think "rationally".
- Turing test approach
	- Requirements include NLP, knowledge representation, automated reasoning, machine learning, compution vision and speech recognition and robotics.
- Agent is just something that acts on the environment i.e it perceives env. through sensors and acts on env. through actuators.
- Computer agents operate autonomously, perceive their environment, persist over a prolonged time period, adapt to change and create and pursue goals.
- Rational agent is one that acts so as to achieve the best outcome or in case of uncertainty, the best expected outcome.
- Percept refers to the content an agent's sensors are perceiving.
- Percept sequence or percepts is the complete history of everything the agent has ever perceived.
- Agent function describes the behaviour of agent which maps any given percept sequence to an action.
- Agent program implements agent function.
- Agent function is an abstract mathematical description whereas agent program is a concrete implementation, running within some physical system.
- Conseqeuntialism means we evaluate an agent's behaviour by its consequences.
- Formal definition of rational agent
	- For each possible percepts, it should select an action that is expected to maximize its PM, given the evidence provided by the percepts and whatever built-in knowledge the agent has.
- Task env. are the "problems" to which rational agents are the "solutions".
- PEAS - Performance, Env., Actuators and Sensors. This is description of the env.
- Fully Observable env. means agent's sensor give it access to ethe complete state of the env. at each point in time.
	- Need not maintain any internal state to keep track of the world.
- Single vs multi agent
- Deterministic env. means that the next state of env. is completely determined by the current state and the action executed by the agent(s).
- Episodic env. means the agent's experience is divided into atomic episoed.
	- The next episode doesn't depend on the actions taken in previous episode.
- Dynamic env. is the env. that changes itself while an agnet is deliberating.
- Semidynamic means agent's performance score changed but env. itself doesn't change.
- Discrete vs continuous (time related)
- Known env. means that the outcomes for all actions are given or agent knows about the laws of physics of the env.
- Agent architecture means a computing device with physical sensors and actuators on which agent program will run.
- Table size for table driven approach is sum(from 1 to T of |P|^t)
- Simple reflex agent selects actions on the basis of the current percept, ignoring the rest of the percept history.
	- Works only if env. is fully oberservable.
- Model-based reflex agents keep track of the part of the world it can't see now.
	- Done by maintaining some sort of internal state that depends on the percept history.
- Transition model is all about the knowledge about "how the world works".
- Sensor model is all about how the state of the world is reflected in the agent's percepts.
